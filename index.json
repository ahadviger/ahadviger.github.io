[{"authors":["admin"],"categories":null,"content":"I am a PhD student in computer vision, focused on event-based visionfor mobile robotics. I am a member of the Laboratory for Autonomous Systems and Mobile Robotics (LAMOR) and a teaching assistant at the University of Zagreb.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ahadviger.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a PhD student in computer vision, focused on event-based visionfor mobile robotics. I am a member of the Laboratory for Autonomous Systems and Mobile Robotics (LAMOR) and a teaching assistant at the University of Zagreb.","tags":null,"title":"Antea Hadviger","type":"authors"},{"authors":["Antea Hadviger","Ivan Marković","Ivan Petrović"],"categories":[],"content":"","date":1601027744,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601027744,"objectID":"530c4eba3c24d7df20254cdd69a18ddb","permalink":"https://ahadviger.github.io/publication/disparity-tracking/","publishdate":"2020-09-25T11:55:44+02:00","relpermalink":"/publication/disparity-tracking/","section":"publication","summary":"Event cameras are biologically inspired sensors that asynchronously detect brightness changes in the scene independently for each pixel. Their output is a stream of events which is reported with a low latency and high temporal resolution of a microsecond, making them superior to standard cameras in highly dynamic scenarios when they are sensitive to motion blur. Event cameras can be used in a wide range of applications, one of them being depth estimation, in both stereo and monocular settings. However, most known event-based depth estimation methods yield sparse depth maps due to the nature of the sparse event stream. We present a novel method that fuses information from both events and standard frames, as well as odometry, to exploit the advantages of both sensors. We propose to estimate dense disparity from standard frames at the point of their availability, predict the disparity using odometry information, and track the disparity asynchronously using optical flow of events between the standard frames. We present the performance of the method through several experiments in various setups, including synthetic data, KITTI dataset enhanced with events, MVSEC dataset, as well as our own stereo event camera recordings.","tags":[],"title":"Stereo dense depth tracking based on optical flow using frames and events","type":"publication"},{"authors":["Antea Hadviger","Ivan Marković","Ivan Petrović"],"categories":[],"content":"","date":1568499125,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568499125,"objectID":"6fda1db0d22cd0593ac9e27bba40977b","permalink":"https://ahadviger.github.io/publication/event-lifetime/","publishdate":"2019-09-15T00:12:05+02:00","relpermalink":"/publication/event-lifetime/","section":"publication","summary":"Event-based cameras are biologically inspired sensors that output asynchronous pixel-wise brightness changes in the scene called events. They have a high dynamic range and temporal resolution of a microsecond, opposed to standard cameras that output frames at fixed frame rates and suffer from motion blur. Forming stereo pairs of such cameras can open novel application possibilities, since for each event depth can be readily estimated; however, to fully exploit asynchronous nature of the sensor and avoid fixed time interval event accumulation, stereo event lifetime estimation should be employed. In this paper, we propose a novel method for event lifetime estimation of stereo event-cameras, allowing generation of sharp gradient images of events that serve as input to disparity estimation methods. Since a single brightness change triggers events in both event-camera sensors, we propose a method for single shot event lifetime and disparity estimation, with association via stereo matching. The proposed method is approximately twice as fast and more accurate than if lifetimes were estimated separately for each sensor and then stereo matched. Results are validated on real-world data through multiple stereo event-camera experiments.","tags":[],"title":"Stereo Event Lifetime and Disparity Estimation for Dynamic Vision Sensors","type":"publication"},{"authors":["Goran Popović","Antea Hadviger","Ivan Marković","Ivan Petrović"],"categories":[],"content":"","date":1535155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535155200,"objectID":"8c8642fd265e8720185a4481fbc81b8f","permalink":"https://ahadviger.github.io/publication/stereo-disparity/","publishdate":"2018-08-25T00:00:00Z","relpermalink":"/publication/stereo-disparity/","section":"publication","summary":"Computationally efficient moving object detection and depth estimation from a stereo camera is an extremely useful tool for many computer vision applications, including robotics and autonomous driving. In this paper we show how moving objects can be densely detected by estimating disparity using an algorithm that improves complexity and accuracy of stereo matching by relying on information from previous frames. The main idea behind this approach is that by using the ego-motion estimation and the disparity map of the previous frame, we can set a prior base that enables us to reduce the complexity of the current frame disparity estimation, subsequently also detecting moving objects in the scene. For each pixel we run a Kalman filter that recursively fuses the disparity prediction and reduced space semi-global matching (SGM) measurements. The proposed algorithm has been implemented and optimized using streaming single instruction multiple data instruction set and multi-threading. Furthermore, in order to estimate the process and measurement noise as reliably as possible, we conduct extensive experiments on the KITTI suite using the ground truth obtained by the 3D laser range sensor. Concerning disparity estimation, compared to the OpenCV SGM implementation, the proposed method yields improvement on the KITTI dataset sequences in terms of both speed and accuracy.","tags":[],"title":"Computationally Efficient Dense Moving Object Detection Based on Reduced Space Disparity Estimation","type":"publication"}]