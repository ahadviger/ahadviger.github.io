[{"authors":["admin"],"categories":null,"content":"I am a PhD student in computer vision, focused on event-based vision for mobile robotics. I am a member of the Laboratory for Autonomous Systems and Mobile Robotics (LAMOR) and a teaching assistant at University of Zagreb.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ahadviger.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a PhD student in computer vision, focused on event-based vision for mobile robotics. I am a member of the Laboratory for Autonomous Systems and Mobile Robotics (LAMOR) and a teaching assistant at University of Zagreb.","tags":null,"title":"Antea Hadviger","type":"authors"},{"authors":["Antea Hadviger","Ivan Marković","Ivan Petrović"],"categories":[],"content":"","date":1568499125,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568499125,"objectID":"6fda1db0d22cd0593ac9e27bba40977b","permalink":"https://ahadviger.github.io/publication/event-lifetime/","publishdate":"2019-09-15T00:12:05+02:00","relpermalink":"/publication/event-lifetime/","section":"publication","summary":"Event-based cameras are biologically inspired sensors that output asynchronous pixel-wise brightness changes in the scene called events. They have a high dynamic range and temporal resolution of a microsecond, opposed to standard cameras that output frames at fixed frame rates and suffer from motion blur. Forming stereo pairs of such cameras can open novel application possibilities, since for each event depth can be readily estimated; however, to fully exploit asynchronous nature of the sensor and avoid fixed time interval event accumulation, stereo event lifetime estimation should be employed. In this paper, we propose a novel method for event lifetime estimation of stereo event-cameras, allowing generation of sharp gradient images of events that serve as input to disparity estimation methods. Since a single brightness change triggers events in both event-camera sensors, we propose a method for single shot event lifetime and disparity estimation, with association via stereo matching. The proposed method is approximately twice as fast and more accurate than if lifetimes were estimated separately for each sensor and then stereo matched. Results are validated on real-world data through multiple stereo event-camera experiments.","tags":[],"title":"Stereo Event Lifetime and Disparity Estimation for Dynamic Vision Sensors","type":"publication"},{"authors":["Goran Popović","Antea Hadviger","Ivan Marković","Ivan Petrović"],"categories":[],"content":"","date":1535155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535155200,"objectID":"8c8642fd265e8720185a4481fbc81b8f","permalink":"https://ahadviger.github.io/publication/stereo-disparity/","publishdate":"2018-08-25T00:00:00Z","relpermalink":"/publication/stereo-disparity/","section":"publication","summary":"Computationally efficient moving object detection and depth estimation from a stereo camera is an extremely useful tool for many computer vision applications, including robotics and autonomous driving. In this paper we show how moving objects can be densely detected by estimating disparity using an algorithm that improves complexity and accuracy of stereo matching by relying on information from previous frames. The main idea behind this approach is that by using the ego-motion estimation and the disparity map of the previous frame, we can set a prior base that enables us to reduce the complexity of the current frame disparity estimation, subsequently also detecting moving objects in the scene. For each pixel we run a Kalman filter that recursively fuses the disparity prediction and reduced space semi-global matching (SGM) measurements. The proposed algorithm has been implemented and optimized using streaming single instruction multiple data instruction set and multi-threading. Furthermore, in order to estimate the process and measurement noise as reliably as possible, we conduct extensive experiments on the KITTI suite using the ground truth obtained by the 3D laser range sensor. Concerning disparity estimation, compared to the OpenCV SGM implementation, the proposed method yields improvement on the KITTI dataset sequences in terms of both speed and accuracy.","tags":[],"title":"Computationally Efficient Dense Moving Object Detection Based on Reduced Space Disparity Estimation","type":"publication"}]